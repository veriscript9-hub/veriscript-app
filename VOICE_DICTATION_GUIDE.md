# üé§ VeriScript - AI Voice Dictation Feature

## üöÄ **Overview**

Voice dictation is VeriScript's **killer feature** that enables doctors to create prescriptions in **30 seconds** (instead of 60) by simply speaking instead of typing.

---

## üéØ **Feature Benefits**

### **For Doctors**
- ‚ö° **50% Faster:** Create prescriptions in 30 seconds instead of 60
- üôå **Hands-Free:** No typing required
- üéØ **More Accurate:** AI understands medical terminology
- üòä **Less Fatigue:** No repetitive typing strain
- üì± **Works Anywhere:** Mobile-friendly

### **Business Impact**
- üöÄ **2x Faster Adoption:** Doctors love speed
- üí∞ **Higher Conversion:** Premium feature drives upgrades
- üèÜ **Competitive Advantage:** Unique in market
- üìà **Better Retention:** Sticky feature
- üí¨ **Word of Mouth:** Doctors share with colleagues

---

## üé§ **How It Works**

### **User Flow**

```
1. Doctor opens prescription form
   ‚Üì
2. Clicks microphone button
   ‚Üì
3. Speaks prescription details
   "Patient Ramesh Kumar, age 45, male.
    Diagnosis: Type 2 Diabetes.
    Medicine: Metformin 500mg, twice daily, after meals, for 30 days.
    Medicine: Glimepiride 2mg, once daily, before breakfast, for 30 days.
    Follow up after 1 month."
   ‚Üì
4. AI processes speech
   ‚Üì
5. Extracts structured data:
   - Patient: Ramesh Kumar, 45, Male
   - Diagnosis: Type 2 Diabetes
   - Medicine 1: Metformin 500mg, 0-1-1, After meals, 30 days
   - Medicine 2: Glimepiride 2mg, 1-0-0, Before breakfast, 30 days
   - Follow-up: 1 month
   ‚Üì
6. Auto-fills form fields
   ‚Üì
7. Doctor reviews and confirms
   ‚Üì
8. Prescription created!
```

---

## üõ†Ô∏è **Technical Implementation**

### **Technology Stack**

#### **Option 1: Web Speech API (Free, Browser-based)**
```javascript
// Pros: Free, works in browser, no API costs
// Cons: Limited accuracy, requires internet, browser-dependent

const recognition = new webkitSpeechRecognition();
recognition.continuous = true;
recognition.interimResults = true;
recognition.lang = 'en-IN'; // Indian English

recognition.onresult = (event) => {
  const transcript = event.results[0][0].transcript;
  processTranscript(transcript);
};
```

#### **Option 2: Google Cloud Speech-to-Text (Recommended)**
```javascript
// Pros: High accuracy, medical terminology support, multi-language
// Cons: Paid (‚Çπ0.006 per 15 seconds)

import speech from '@google-cloud/speech';

const client = new speech.SpeechClient();

const audio = {
  content: audioBytes.toString('base64'),
};

const config = {
  encoding: 'LINEAR16',
  sampleRateHertz: 16000,
  languageCode: 'en-IN',
  model: 'medical_dictation', // Medical-specific model
  useEnhanced: true,
};

const [response] = await client.recognize({ audio, config });
const transcript = response.results
  .map(result => result.alternatives[0].transcript)
  .join('\n');
```

#### **Option 3: OpenAI Whisper API (Best Accuracy)**
```javascript
// Pros: Best accuracy, understands context, multi-language
// Cons: Paid ($0.006 per minute)

const formData = new FormData();
formData.append('file', audioFile);
formData.append('model', 'whisper-1');
formData.append('language', 'en');

const response = await fetch('https://api.openai.com/v1/audio/transcriptions', {
  method: 'POST',
  headers: {
    'Authorization': `Bearer ${OPENAI_API_KEY}`,
  },
  body: formData,
});

const { text } = await response.json();
```

---

## ü§ñ **AI Processing with GPT-4**

### **Extract Structured Data from Transcript**

```javascript
async function processTranscript(transcript) {
  const prompt = `
You are a medical prescription assistant. Extract structured data from this doctor's dictation:

"${transcript}"

Return JSON with this exact structure:
{
  "patient": {
    "name": "string",
    "age": number,
    "gender": "Male/Female/Other"
  },
  "diagnosis": "string",
  "medicines": [
    {
      "name": "string",
      "dosage": "string",
      "frequency": "string",
      "timing": "string (Before/After meals)",
      "duration": "string",
      "morning": number,
      "afternoon": number,
      "night": number,
      "instructions": "string"
    }
  ],
  "notes": "string",
  "followUp": "string"
}

Rules:
- Extract medicine dosage from name (e.g., "Paracetamol 500mg" ‚Üí name: "Paracetamol", dosage: "500mg")
- Convert frequency to morning-afternoon-night format (e.g., "twice daily" ‚Üí 1-0-1)
- If timing not specified, default to "After meals"
- If duration not specified, default to "5 days"
`;

  const response = await fetch('https://api.openai.com/v1/chat/completions', {
    method: 'POST',
    headers: {
      'Content-Type': 'application/json',
      'Authorization': `Bearer ${OPENAI_API_KEY}`,
    },
    body: JSON.stringify({
      model: 'gpt-4',
      messages: [
        { role: 'system', content: 'You are a medical prescription assistant.' },
        { role: 'user', content: prompt }
      ],
      temperature: 0.1, // Low temperature for consistency
    }),
  });

  const data = await response.json();
  const extractedData = JSON.parse(data.choices[0].message.content);
  
  return extractedData;
}
```

---

## üì± **UI/UX Design**

### **Voice Button States**

```css
/* Idle State */
.voice-btn {
  background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
  border-radius: 50%;
  width: 80px;
  height: 80px;
  display: flex;
  align-items: center;
  justify-content: center;
  cursor: pointer;
  transition: all 0.3s ease;
  box-shadow: 0 4px 20px rgba(102, 126, 234, 0.3);
}

.voice-btn:hover {
  transform: scale(1.1);
  box-shadow: 0 6px 30px rgba(102, 126, 234, 0.5);
}

/* Listening State */
.voice-btn.listening {
  animation: pulse 1.5s infinite;
  background: linear-gradient(135deg, #ef4444 0%, #dc2626 100%);
}

@keyframes pulse {
  0%, 100% {
    transform: scale(1);
    box-shadow: 0 4px 20px rgba(239, 68, 68, 0.3);
  }
  50% {
    transform: scale(1.1);
    box-shadow: 0 6px 40px rgba(239, 68, 68, 0.6);
  }
}

/* Processing State */
.voice-btn.processing {
  background: linear-gradient(135deg, #f59e0b 0%, #d97706 100%);
  animation: spin 1s linear infinite;
}

@keyframes spin {
  from { transform: rotate(0deg); }
  to { transform: rotate(360deg); }
}
```

### **Voice Modal**

```html
<div class="voice-modal" id="voiceModal">
  <div class="voice-modal-content">
    <!-- Header -->
    <div class="voice-header">
      <h3>üé§ Voice Dictation</h3>
      <button class="close-btn" onclick="closeVoiceModal()">‚úï</button>
    </div>
    
    <!-- Status -->
    <div class="voice-status">
      <div class="status-icon" id="statusIcon">üé§</div>
      <div class="status-text" id="statusText">Ready to listen</div>
    </div>
    
    <!-- Waveform Animation -->
    <div class="waveform" id="waveform">
      <div class="wave"></div>
      <div class="wave"></div>
      <div class="wave"></div>
      <div class="wave"></div>
      <div class="wave"></div>
    </div>
    
    <!-- Transcript -->
    <div class="transcript-container">
      <div class="transcript-label">What you said:</div>
      <div class="transcript-text" id="transcriptText">
        Start speaking...
      </div>
    </div>
    
    <!-- Tips -->
    <div class="voice-tips">
      <div class="tip">üí° Speak clearly and at normal pace</div>
      <div class="tip">üí° Include patient name, age, gender</div>
      <div class="tip">üí° Say medicine name, dosage, frequency</div>
      <div class="tip">üí° Mention timing (before/after meals)</div>
    </div>
    
    <!-- Actions -->
    <div class="voice-actions">
      <button class="btn btn-secondary" onclick="stopListening()">
        ‚èπÔ∏è Stop
      </button>
      <button class="btn btn-primary" onclick="processVoice()">
        ‚úì Process
      </button>
    </div>
  </div>
</div>
```

---

## üíª **Complete Implementation Code**

### **HTML (Add to create-prescription.html)**

```html
<!-- Voice Button (Floating) -->
<button class="voice-fab" onclick="openVoiceModal()" title="Voice Dictation">
  üé§
</button>

<!-- Voice Modal -->
<div class="voice-modal" id="voiceModal">
  <!-- Modal content as shown above -->
</div>
```

### **CSS (Add to main.css)**

```css
/* Voice FAB */
.voice-fab {
  position: fixed;
  bottom: 2rem;
  right: 2rem;
  width: 70px;
  height: 70px;
  border-radius: 50%;
  background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
  color: white;
  font-size: 2rem;
  border: none;
  cursor: pointer;
  box-shadow: 0 4px 20px rgba(102, 126, 234, 0.4);
  transition: all 0.3s ease;
  z-index: 999;
}

.voice-fab:hover {
  transform: scale(1.1);
  box-shadow: 0 6px 30px rgba(102, 126, 234, 0.6);
}

/* Voice Modal */
.voice-modal {
  display: none;
  position: fixed;
  top: 0;
  left: 0;
  right: 0;
  bottom: 0;
  background: rgba(0, 0, 0, 0.7);
  backdrop-filter: blur(4px);
  z-index: 1000;
  align-items: center;
  justify-content: center;
  padding: 2rem;
}

.voice-modal.active {
  display: flex;
}

.voice-modal-content {
  background: white;
  border-radius: 2rem;
  padding: 3rem;
  max-width: 600px;
  width: 100%;
  animation: slideUp 0.3s ease;
}

/* Waveform Animation */
.waveform {
  display: flex;
  align-items: center;
  justify-content: center;
  gap: 0.5rem;
  height: 100px;
  margin: 2rem 0;
}

.wave {
  width: 8px;
  height: 20px;
  background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
  border-radius: 4px;
  animation: wave 1s ease-in-out infinite;
}

.wave:nth-child(1) { animation-delay: 0s; }
.wave:nth-child(2) { animation-delay: 0.1s; }
.wave:nth-child(3) { animation-delay: 0.2s; }
.wave:nth-child(4) { animation-delay: 0.3s; }
.wave:nth-child(5) { animation-delay: 0.4s; }

@keyframes wave {
  0%, 100% { height: 20px; }
  50% { height: 60px; }
}

/* Transcript */
.transcript-container {
  background: #f8fafc;
  border-radius: 1rem;
  padding: 1.5rem;
  margin: 2rem 0;
  min-height: 150px;
}

.transcript-label {
  font-size: 0.875rem;
  font-weight: 600;
  color: #64748b;
  margin-bottom: 0.5rem;
}

.transcript-text {
  font-size: 1rem;
  color: #1e293b;
  line-height: 1.6;
}

/* Voice Tips */
.voice-tips {
  background: #eff6ff;
  border-radius: 1rem;
  padding: 1.5rem;
  margin: 2rem 0;
}

.tip {
  font-size: 0.875rem;
  color: #1e40af;
  margin-bottom: 0.5rem;
}

.tip:last-child {
  margin-bottom: 0;
}
```

### **JavaScript (Add to create-prescription.html)**

```javascript
// Voice Dictation Implementation
let recognition = null;
let isListening = false;
let fullTranscript = '';

// Initialize Speech Recognition
function initVoiceRecognition() {
  if ('webkitSpeechRecognition' in window) {
    recognition = new webkitSpeechRecognition();
    recognition.continuous = true;
    recognition.interimResults = true;
    recognition.lang = 'en-IN'; // Indian English
    
    recognition.onstart = () => {
      isListening = true;
      updateVoiceStatus('listening', 'üé§ Listening...', 'Speak now');
    };
    
    recognition.onresult = (event) => {
      let interimTranscript = '';
      let finalTranscript = '';
      
      for (let i = event.resultIndex; i < event.results.length; i++) {
        const transcript = event.results[i][0].transcript;
        if (event.results[i].isFinal) {
          finalTranscript += transcript + ' ';
        } else {
          interimTranscript += transcript;
        }
      }
      
      fullTranscript += finalTranscript;
      document.getElementById('transcriptText').textContent = 
        fullTranscript + interimTranscript;
    };
    
    recognition.onerror = (event) => {
      console.error('Speech recognition error:', event.error);
      updateVoiceStatus('error', '‚ùå Error', event.error);
    };
    
    recognition.onend = () => {
      isListening = false;
      if (fullTranscript) {
        updateVoiceStatus('ready', '‚úì Ready to process', 'Click Process button');
      }
    };
  } else {
    alert('Speech recognition not supported in this browser. Please use Chrome.');
  }
}

// Open Voice Modal
function openVoiceModal() {
  document.getElementById('voiceModal').classList.add('active');
  initVoiceRecognition();
  startListening();
}

// Close Voice Modal
function closeVoiceModal() {
  stopListening();
  document.getElementById('voiceModal').classList.remove('active');
  fullTranscript = '';
}

// Start Listening
function startListening() {
  if (recognition && !isListening) {
    fullTranscript = '';
    document.getElementById('transcriptText').textContent = 'Listening...';
    recognition.start();
  }
}

// Stop Listening
function stopListening() {
  if (recognition && isListening) {
    recognition.stop();
  }
}

// Update Voice Status
function updateVoiceStatus(state, icon, text) {
  document.getElementById('statusIcon').textContent = icon;
  document.getElementById('statusText').textContent = text;
  
  const waveform = document.getElementById('waveform');
  if (state === 'listening') {
    waveform.style.display = 'flex';
  } else {
    waveform.style.display = 'none';
  }
}

// Process Voice with AI
async function processVoice() {
  if (!fullTranscript) {
    utils.showToast('Please speak something first', 'error');
    return;
  }
  
  updateVoiceStatus('processing', '‚è≥ Processing...', 'AI is analyzing your speech');
  
  try {
    // Call OpenAI GPT-4 to extract structured data
    const extractedData = await extractPrescriptionData(fullTranscript);
    
    // Fill form fields
    fillFormWithVoiceData(extractedData);
    
    // Close modal
    closeVoiceModal();
    
    // Show success
    utils.showToast('Prescription filled from voice!', 'success');
    
  } catch (error) {
    console.error('Error processing voice:', error);
    utils.showToast('Error processing voice. Please try again.', 'error');
    updateVoiceStatus('error', '‚ùå Error', 'Failed to process');
  }
}

// Extract Prescription Data using AI
async function extractPrescriptionData(transcript) {
  const prompt = `
You are a medical prescription assistant. Extract structured data from this doctor's dictation:

"${transcript}"

Return ONLY valid JSON with this exact structure (no markdown, no code blocks):
{
  "patient": {
    "name": "string",
    "age": number,
    "gender": "Male/Female/Other"
  },
  "diagnosis": "string",
  "medicines": [
    {
      "name": "string (medicine name without dosage)",
      "dosage": "string (e.g., 500mg, 2mg)",
      "frequency": "string (Once daily/Twice daily/Thrice daily)",
      "timing": "string (Before meals/After meals/With meals)",
      "duration": "string (e.g., 5 days, 1 month)",
      "morning": number (0, 1, or 2),
      "afternoon": number (0, 1, or 2),
      "night": number (0, 1, or 2),
      "instructions": "string"
    }
  ],
  "notes": "string",
  "followUp": "string"
}

Rules:
- Extract medicine name and dosage separately
- Convert frequency to morning-afternoon-night format:
  * "once daily" ‚Üí 1-0-0 or 0-1-0 or 0-0-1 (based on timing)
  * "twice daily" ‚Üí 1-0-1
  * "thrice daily" ‚Üí 1-1-1
  * "four times daily" ‚Üí 1-1-1-1 (use morning=1, afternoon=1, night=2)
- If timing not specified, default to "After meals"
- If duration not specified, default to "5 days"
- Return ONLY the JSON object, no other text
`;

  const response = await fetch('https://api.openai.com/v1/chat/completions', {
    method: 'POST',
    headers: {
      'Content-Type': 'application/json',
      'Authorization': `Bearer ${OPENAI_API_KEY}`, // Add your API key
    },
    body: JSON.stringify({
      model: 'gpt-4',
      messages: [
        { 
          role: 'system', 
          content: 'You are a medical prescription assistant. Always return valid JSON only.' 
        },
        { role: 'user', content: prompt }
      ],
      temperature: 0.1,
    }),
  });

  const data = await response.json();
  const content = data.choices[0].message.content;
  
  // Remove markdown code blocks if present
  const jsonString = content.replace(/```json\n?/g, '').replace(/```\n?/g, '').trim();
  
  return JSON.parse(jsonString);
}

// Fill Form with Voice Data
function fillFormWithVoiceData(data) {
  // Patient Information
  if (data.patient) {
    document.getElementById('patientName').value = data.patient.name || '';
    document.getElementById('patientAge').value = data.patient.age || '';
    document.getElementById('patientGender').value = data.patient.gender || '';
  }
  
  // Diagnosis
  if (data.diagnosis) {
    document.getElementById('diagnosis').value = data.diagnosis;
  }
  
  // Notes
  if (data.notes) {
    document.getElementById('notes').value = data.notes;
  }
  
  // Follow-up
  if (data.followUp) {
    // Parse follow-up date (e.g., "1 month" ‚Üí date 1 month from now)
    const followUpDate = parseFollowUpDate(data.followUp);
    if (followUpDate) {
      document.getElementById('followupDate').value = followUpDate;
    }
  }
  
  // Medicines
  if (data.medicines && data.medicines.length > 0) {
    // Clear existing medicines
    document.getElementById('medicinesContainer').innerHTML = '';
    
    // Add each medicine
    data.medicines.forEach((medicine, index) => {
      addMedicine();
      
      // Wait for DOM to update
      setTimeout(() => {
        const medicineCard = document.querySelectorAll('.medicine-card')[index];
        if (medicineCard) {
          medicineCard.querySelector('.medicine-name').value = 
            `${medicine.name} ${medicine.dosage}`;
          medicineCard.querySelector('.medicine-frequency').value = 
            medicine.frequency || '';
          medicineCard.querySelector('.medicine-duration').value = 
            medicine.duration || '';
          medicineCard.querySelector('.medicine-morning').value = 
            medicine.morning || 0;
          medicineCard.querySelector('.medicine-afternoon').value = 
            medicine.afternoon || 0;
          medicineCard.querySelector('.medicine-night').value = 
            medicine.night || 0;
          medicineCard.querySelector('.medicine-instructions').value = 
            medicine.timing + (medicine.instructions ? '. ' + medicine.instructions : '');
        }
      }, 100);
    });
  }
  
  // Update preview
  setTimeout(() => {
    updatePreview();
  }, 200);
}

// Parse Follow-up Date
function parseFollowUpDate(followUpText) {
  const today = new Date();
  const text = followUpText.toLowerCase();
  
  // Extract number and unit
  const match = text.match(/(\d+)\s*(day|week|month|year)s?/);
  if (!match) return null;
  
  const amount = parseInt(match[1]);
  const unit = match[2];
  
  let date = new Date(today);
  
  switch (unit) {
    case 'day':
      date.setDate(date.getDate() + amount);
      break;
    case 'week':
      date.setDate(date.getDate() + (amount * 7));
      break;
    case 'month':
      date.setMonth(date.getMonth() + amount);
      break;
    case 'year':
      date.setFullYear(date.getFullYear() + amount);
      break;
  }
  
  return date.toISOString().split('T')[0];
}

// Initialize on page load
window.addEventListener('DOMContentLoaded', () => {
  initVoiceRecognition();
});
```

---

## üìä **Pricing Strategy**

### **Freemium Model**

| Plan | Voice Minutes/Month | Price |
|------|---------------------|-------|
| **Free** | 10 minutes | ‚Çπ0 |
| **Basic** | 100 minutes | ‚Çπ299 |
| **Pro** | Unlimited | ‚Çπ599 |
| **Enterprise** | Unlimited + Custom | ‚Çπ999 |

### **Cost Analysis**

**Using OpenAI Whisper:**
- Cost: $0.006 per minute
- Average prescription: 1 minute
- Cost per prescription: ‚Çπ0.50
- Margin: ‚Çπ299 - (100 √ó ‚Çπ0.50) = ‚Çπ249 (83% margin)

**Using Google Speech-to-Text:**
- Cost: ‚Çπ0.006 per 15 seconds = ‚Çπ0.024 per minute
- Average prescription: 1 minute
- Cost per prescription: ‚Çπ0.024
- Margin: ‚Çπ299 - (100 √ó ‚Çπ0.024) = ‚Çπ296.60 (99% margin)

**Recommendation:** Use Google Speech-to-Text for better margins

---

## üéØ **Marketing Angle**

### **Tagline**
**"Create Prescriptions in 30 Seconds - Just Speak!"**

### **Key Messages**
1. **"Speak, Don't Type"** - 50% faster than typing
2. **"Hands-Free Healthcare"** - Focus on patients, not paperwork
3. **"AI Understands Medical Terms"** - Trained on medical vocabulary
4. **"Works in Any Language"** - Hindi, English, Tamil, Telugu, etc.
5. **"No Learning Curve"** - Just speak naturally

### **Demo Script**
```
"Watch me create a prescription in 30 seconds using just my voice.

[Clicks microphone]

'Patient Ramesh Kumar, age 45, male. 
Diagnosis: Type 2 Diabetes. 
Medicine: Metformin 500mg, twice daily, after meals, for 30 days. 
Medicine: Glimepiride 2mg, once daily, before breakfast, for 30 days. 
Follow up after 1 month.'

[Clicks process]

Done! Prescription ready in 30 seconds. 
No typing. No hassle. Just speak.

Try VeriScript Voice today!"
```

---

## üöÄ **Implementation Roadmap**

### **Phase 1: MVP (Week 1-2)**
- [ ] Integrate Web Speech API
- [ ] Basic voice recording
- [ ] Simple transcript display
- [ ] Manual form filling from transcript

### **Phase 2: AI Integration (Week 3-4)**
- [ ] Integrate OpenAI GPT-4
- [ ] Auto-extract structured data
- [ ] Auto-fill form fields
- [ ] Handle edge cases

### **Phase 3: Enhancement (Week 5-6)**
- [ ] Multi-language support
- [ ] Medical terminology training
- [ ] Voice commands (e.g., "Add medicine")
- [ ] Offline mode

### **Phase 4: Mobile App (Week 7-8)**
- [ ] React Native app
- [ ] Native voice recording
- [ ] Better audio quality
- [ ] Background recording

---

## üì± **Mobile App Considerations**

### **React Native Implementation**

```javascript
import Voice from '@react-native-voice/voice';

// Start Recording
const startRecording = async () => {
  try {
    await Voice.start('en-IN');
  } catch (error) {
    console.error(error);
  }
};

// Stop Recording
const stopRecording = async () => {
  try {
    await Voice.stop();
  } catch (error) {
    console.error(error);
  }
};

// Handle Results
Voice.onSpeechResults = (event) => {
  const transcript = event.value[0];
  processTranscript(transcript);
};
```

---

## üéØ **Success Metrics**

### **Track These KPIs**

1. **Adoption Rate**
   - % of doctors using voice
   - Voice prescriptions vs typed
   - Daily active voice users

2. **Time Savings**
   - Average time per prescription
   - Time saved per doctor
   - Total time saved (all doctors)

3. **Accuracy**
   - % of prescriptions needing edits
   - Common errors
   - User satisfaction

4. **Business Impact**
   - Conversion to paid plans
   - Retention rate
   - Referral rate
   - Revenue per user

---

## üí° **Pro Tips**

### **For Best Results**

1. **Speak Clearly**
   - Normal pace, not too fast
   - Clear pronunciation
   - Avoid background noise

2. **Use Structure**
   - Start with patient details
   - Then diagnosis
   - Then medicines one by one
   - End with follow-up

3. **Be Specific**
   - Include dosage with medicine name
   - Mention timing (before/after meals)
   - State duration clearly

4. **Review Before Submitting**
   - Always check AI-filled data
   - Correct any errors
   - Add missing details

---

## üéâ **Competitive Advantage**

### **Why This Wins**

1. **First in Market**
   - No competitor has voice dictation
   - Unique selling point
   - Patent opportunity

2. **Massive Time Savings**
   - 50% faster than typing
   - Doctors love speed
   - Sticky feature

3. **Network Effects**
   - Doctors share with colleagues
   - Word of mouth spreads
   - Viral growth potential

4. **Premium Feature**
   - Drives upgrades to paid plans
   - Higher revenue per user
   - Better unit economics

5. **Future-Proof**
   - AI will only get better
   - More languages coming
   - More features possible

---

<div align="center">

**üé§ Voice Dictation: VeriScript's Killer Feature**

*Create Prescriptions in 30 Seconds - Just Speak!*

**50% Faster | Hands-Free | AI-Powered**

</div>
